from typing import Dict, Any, List, Optional

from src.components import (
    AnswerExtractor,
    ModelWrapper,
    QuestionClassifier,
    SafetyClassifier,
    SemanticContextFilter,
    PromptSelector,
    QdrantRetriever,
)
from src.utils import DynamicChoicesFormatter, QuestionDifficulty


class ConfidenceScorer:

    @staticmethod
    def calculate_confidence(
        model_response: str, extracted_answer: str, valid_labels: List[str]
    ) -> float:

        if not model_response or not extracted_answer:
            return 0.0

        confidence = 0.5  # Base confidence

        # 1. ƒê√°p √°n xu·∫•t hi·ªán nhi·ªÅu l·∫ßn (max +0.3)
        answer_count = model_response.upper().count(extracted_answer.upper())
        confidence += min(answer_count * 0.1, 0.3)

        # 2. C√≥ gi·∫£i th√≠ch r√µ r√†ng (length > 50 chars)
        if len(model_response) > 50:
            confidence += 0.1

        # 3. C√≥ t·ª´ kh√≥a x√°c ƒë·ªãnh
        positive_keywords = ["ƒê√°p √°n l√†", "Ch·∫Øc ch·∫Øn", "R√µ r√†ng", "K·∫øt lu·∫≠n"]
        if any(kw in model_response for kw in positive_keywords):
            confidence += 0.1

        # 4. Kh√¥ng c√≥ t·ª´ kh√≥a kh√¥ng ch·∫Øc ch·∫Øn
        negative_keywords = ["c√≥ th·ªÉ", "kh√¥ng ch·∫Øc", "kh√≥ n√≥i", "kh√¥ng r√µ"]
        if any(kw in model_response.lower() for kw in negative_keywords):
            confidence -= 0.2

        # 5. ƒê√°p √°n ·ªü cu·ªëi response (th∆∞·ªùng l√† k·∫øt lu·∫≠n)
        if model_response.strip().endswith(extracted_answer):
            confidence += 0.1

        return max(0.0, min(1.0, confidence))


class HybridModelSelector:
    """
    L·ª±a ch·ªçn model ph√π h·ª£p cho 5 lo·∫°i c√¢u h·ªèi m·ªõi:
    RAG, COMPULSORY, STEM, PRECISION_CRITICAL, MULTI_DOMAIN
    """

    @staticmethod
    def select_model(
        question_type: str,
        difficulty: str,
        context_length: int = 0,
        strategy: str = "hybrid",
        subtype: str = "general",
    ) -> str:

        if strategy == "cost-optimized":
            return HybridModelSelector._cost_optimized(
                question_type, difficulty, context_length, subtype
            )
        elif strategy == "quality-optimized":
            return HybridModelSelector._quality_optimized(
                question_type, difficulty, context_length, subtype
            )
        else:  # hybrid (default)
            return HybridModelSelector._hybrid_strategy(
                question_type, difficulty, context_length, subtype
            )

    @staticmethod
    def _cost_optimized(
        question_type: str, difficulty: str, context_length: int, subtype: str
    ) -> str:
        """Chi·∫øn l∆∞·ª£c t·ªëi ∆∞u chi ph√≠"""
        if question_type in ["STEM", "PRECISION_CRITICAL"]:
            return "large"  # C·∫ßn ƒë·ªô ch√≠nh x√°c cao
        elif question_type == "COMPULSORY":
            return "large"  # An to√†n quan tr·ªçng
        elif question_type == "RAG":
            return "small"  # Context ƒë√£ filter, small ƒë·ªß
        elif question_type == "MULTI_DOMAIN":
            return difficulty  # D·ª±a v√†o ƒë·ªô kh√≥
        return "small"

    @staticmethod
    def _quality_optimized(
        question_type: str, difficulty: str, context_length: int, subtype: str
    ) -> str:
        """Chi·∫øn l∆∞·ª£c t·ªëi ∆∞u ch·∫•t l∆∞·ª£ng"""
        return "large"  # T·∫•t c·∫£ d√πng large

    @staticmethod
    def _hybrid_strategy(
        question_type: str, difficulty: str, context_length: int, subtype: str
    ) -> str:
        """Chi·∫øn l∆∞·ª£c c√¢n b·∫±ng (m·∫∑c ƒë·ªãnh)"""

        # STEM: Lu√¥n large (ƒë·ªô ch√≠nh x√°c quan tr·ªçng)
        if question_type == "STEM":
            return "large"

        # PRECISION_CRITICAL: Lu√¥n large (ƒë·ªô ch√≠nh x√°c tuy·ªát ƒë·ªëi)
        elif question_type == "PRECISION_CRITICAL":
            return "large"

        # COMPULSORY: Lu√¥n large (an to√†n quan tr·ªçng)
        elif question_type == "COMPULSORY":
            return "large"

        # RAG: D·ª±a v√†o ƒë·ªô d√†i context
        elif question_type == "RAG":
            if context_length < 1000:
                return "small"
            else:
                return "large"

        # MULTI_DOMAIN: D·ª±a v√†o ƒë·ªô kh√≥ v√† subtype
        elif question_type == "MULTI_DOMAIN":
            # Tri·∫øt h·ªçc, l·ªãch s·ª≠ ph·ª©c t·∫°p ‚Üí large
            if subtype in ["tri·∫øt h·ªçc", "l·ªãch s·ª≠"] or difficulty == "large":
                return "large"
            else:
                return "small_with_fallback"

        return "large"  # Default


class HybridPipeline:
    """
    Pipeline t·ªëi ∆∞u v·ªõi hybrid model selection
    """

    def __init__(
        self,
        strategy: str = "hybrid",
        large_model_name: str = "large",
        small_model_name: str = "small",
        compulsory_safety_mode: str = "keyword",
        use_qdrant_rag: bool = True,
        qdrant_top_k: int = 5,
        qdrant_max_chars: int = 2000,
    ):
        """
        Args:
            strategy: Chi·∫øn l∆∞·ª£c l·ª±a ch·ªçn model
                     - "cost-optimized": T·ªëi ∆∞u chi ph√≠
                     - "quality-optimized": T·ªëi ∆∞u ch·∫•t l∆∞·ª£ng
                     - "hybrid": C√¢n b·∫±ng (m·∫∑c ƒë·ªãnh)
            large_model_name: T√™n large model (default: "large" cho VNPT, "gpt-4o-mini" cho OpenAI)
            small_model_name: T√™n small model (default: "small" cho VNPT, "gpt-3.5-turbo" cho OpenAI)
            compulsory_safety_mode: Ch·∫ø ƒë·ªô safety check cho c√¢u h·ªèi COMPULSORY
                        - "keyword": D√πng keyword matching (nhanh, m·∫∑c ƒë·ªãnh)
                        - "model": D√πng model verification (ch√≠nh x√°c h∆°n)
            use_qdrant_rag: C√≥ s·ª≠ d·ª•ng Qdrant RAG cho COMPULSORY v√† MULTI_DOMAIN kh√¥ng
            qdrant_top_k: S·ªë documents l·∫•y t·ª´ Qdrant
            qdrant_max_chars: ƒê·ªô d√†i t·ªëi ƒëa c·ªßa context t·ª´ Qdrant
        """
        self.strategy = strategy
        self.large_model_name = large_model_name
        self.small_model_name = small_model_name
        self.small_model = None  # Lazy loading
        self.large_model = None  # Lazy loading
        self.compulsory_safety_mode = compulsory_safety_mode
        self.use_qdrant_rag = use_qdrant_rag
        self.qdrant_top_k = qdrant_top_k
        self.qdrant_max_chars = qdrant_max_chars

        self.classifier = QuestionClassifier()
        self.context_filter = SemanticContextFilter()
        self.safety_classifier = SafetyClassifier()
        self.prompt_selector = PromptSelector()

        # Kh·ªüi t·∫°o QdrantRetriever n·∫øu c·∫ßn
        self.qdrant_retriever = None
        if self.use_qdrant_rag:
            try:
                print("Initializing QdrantRetriever...")
                self.qdrant_retriever = QdrantRetriever()
                print("‚úì QdrantRetriever initialized successfully")
            except Exception as e:
                print(f"‚ö†Ô∏è Warning: Could not initialize QdrantRetriever: {e}")
                print("Continuing without Qdrant RAG support...")
                self.use_qdrant_rag = False

        self.answer_extractor = AnswerExtractor()
        self.confidence_scorer = ConfidenceScorer()
        self.formatter = DynamicChoicesFormatter()

        # Statistics
        self.stats = {
            "small_used": 0,
            "large_used": 0,
            "fallback_triggered": 0,
            "rate_limit_fallback": 0,
            "compulsory_detected": 0,
            "qdrant_rag_used": 0,
            "total_processed": 0,
        }

    def _get_model(self, model_type: str) -> ModelWrapper:
        """Lazy loading models"""
        if model_type == "small":
            if self.small_model is None:
                self.small_model = ModelWrapper(model_type=self.small_model_name)
            return self.small_model
        else:
            if self.large_model is None:
                self.large_model = ModelWrapper(model_type=self.large_model_name)
            return self.large_model

    def _process_compulsory_question(
        self,
        qid: str,
        question: str,
        choices: List[str],
        ground_truth: str = None,
        subtype: str = "safety",
        verbose: bool = False,
    ) -> Dict[str, Any]:
        """
        X·ª≠ l√Ω c√¢u h·ªèi COMPULSORY (Safety/Refusal/Law)
        S·ª≠ d·ª•ng safety_classifier v√† Qdrant RAG
        """
        if verbose:
            print(f"üîí Processing COMPULSORY question (subtype={subtype})")

        # X√°c ƒë·ªãnh c√≥ d√πng model verification kh√¥ng
        use_model_verification = self.compulsory_safety_mode == "model"

        # N·∫øu d√πng model verification, c·∫ßn model_wrapper
        model_wrapper = None
        if use_model_verification:
            model_wrapper = self._get_model("small")

        # G·ªçi safety classifier
        safety_result = self.safety_classifier.classify_safety(
            question=question,
            choices=choices,
            model_wrapper=model_wrapper,
            verbose=verbose,
            use_model_verification=use_model_verification,
        )

        if not safety_result["is_safe"]:
            # C√≥ ƒë√°p √°n unsafe/refusal trong choices ‚Üí ch·ªçn lu√¥n ƒë√°p √°n ƒë√≥
            if verbose:
                print("‚ö†Ô∏è Safety/Refusal answer detected in choices!")
                print(f"Auto-selecting answer: {safety_result['unsafe_answer']}")

            self.stats["compulsory_detected"] += 1
            self.stats["total_processed"] += 1

            result = {
                "qid": qid,
                "predicted": safety_result["unsafe_answer"],
                "raw_response": f"COMPULSORY: {safety_result.get('raw_response', 'keyword_detected')}",
                "model_used": "safety_classifier",
                "confidence": safety_result["confidence"],
                "ground_truth": ground_truth,
                "type": "COMPULSORY",
                "subtype": subtype,
                "difficulty": "compulsory",
                "extraction_failed": False,
                "safety_method": safety_result["method"],
                "qdrant_used": False,
            }

            if ground_truth:
                result["correct"] = result["predicted"] == ground_truth
            else:
                result["correct"] = None

            return result

        # N·∫øu kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c ƒë√°p √°n refusal r√µ r√†ng, d√πng model v·ªõi RAG
        if verbose:
            print("No clear refusal answer detected, using model with RAG...")

        # Retrieve context t·ª´ Qdrant
        qdrant_context = self._retrieve_qdrant_context(
            question=question,
            question_type="COMPULSORY",
            subtype=subtype,
            verbose=verbose,
        )

        # Build prompt cho COMPULSORY v·ªõi context (n·∫øu c√≥)
        prompt = self.prompt_selector.select_prompt(
            question_type="COMPULSORY",
            question=question,
            choices=choices,
            context=qdrant_context,
            subtype=subtype,
            model_type="large",
        )

        # G·ªçi large model (COMPULSORY c·∫ßn ƒë·ªô ch√≠nh x√°c cao)
        result = self._get_model_response(
            model_type="large",
            prompt=prompt,
            question_type="COMPULSORY",
            choices=choices,
            verbose=verbose,
        )

        # Add metadata
        result["qid"] = qid
        result["ground_truth"] = ground_truth
        result["type"] = "COMPULSORY"
        result["subtype"] = subtype
        result["difficulty"] = "compulsory"
        result["qdrant_used"] = qdrant_context is not None

        if ground_truth and result["predicted"]:
            result["correct"] = result["predicted"] == ground_truth
        else:
            result["correct"] = None

        self.stats["compulsory_detected"] += 1
        self.stats["total_processed"] += 1

        return result

    def _retrieve_qdrant_context(
        self,
        question: str,
        question_type: str,
        subtype: str,
        verbose: bool = False,
    ) -> Optional[str]:
        """
        Retrieve context t·ª´ Qdrant cho c√°c c√¢u h·ªèi COMPULSORY v√† MULTI_DOMAIN

        Returns:
            Context string ho·∫∑c None n·∫øu kh√¥ng retrieve ƒë∆∞·ª£c
        """
        if not self.use_qdrant_rag or self.qdrant_retriever is None:
            return None

        # Ch·ªâ retrieve cho COMPULSORY v√† MULTI_DOMAIN
        if question_type not in ["COMPULSORY", "MULTI_DOMAIN"]:
            return None

        try:
            if verbose:
                print(
                    f"üìö Retrieving context from Qdrant (type={question_type}, subtype={subtype})..."
                )

            rag_result = self.qdrant_retriever.retrieve_and_format(
                question=question,
                question_type=question_type,
                subtype=subtype,
                top_k=self.qdrant_top_k,
                max_chars=self.qdrant_max_chars,
                include_scores=False,
            )

            context = rag_result.get("context", "")

            if context and context.strip():
                self.stats["qdrant_rag_used"] += 1

                if verbose:
                    print(f"‚úì Retrieved {rag_result['num_documents']} documents")
                    print(f"  Avg score: {rag_result['avg_score']:.4f}")
                    print(f"  Context length: {len(context)} chars")

                return context
            else:
                if verbose:
                    print("‚ö†Ô∏è No relevant context found in Qdrant")
                return None

        except Exception as e:
            if verbose:
                print(f"‚ö†Ô∏è Error retrieving from Qdrant: {e}")
            return None

    def process_single(
        self, item: Dict[str, Any], verbose: bool = False
    ) -> Dict[str, Any]:

        qid = item.get("qid", "unknown")
        question = item.get("question", "").strip()
        choices = item.get("choices", [])
        ground_truth = (
            item.get("answer", "").strip().upper() if "answer" in item else None
        )

        if verbose:
            print(f"\n{'='*70}")
            print(f"QID: {qid}")
            print(f"Question: {question[:100]}...")

        # 1. Ph√¢n lo·∫°i c√¢u h·ªèi (v·ªõi choices ƒë·ªÉ detect COMPULSORY)
        classification = self.classifier.classify(question, choices)
        question_type = classification["type"]
        subtype = classification.get("subtype", "general")

        # 2. X·ª≠ l√Ω ƒë·∫∑c bi·ªát cho COMPULSORY (Safety/Refusal)
        if question_type == "COMPULSORY":
            return self._process_compulsory_question(
                qid=qid,
                question=question,
                choices=choices,
                ground_truth=ground_truth,
                subtype=subtype,
                verbose=verbose,
            )

        # 3. Ph√¢n lo·∫°i ƒë·ªô kh√≥
        difficulty = QuestionDifficulty.classify_difficulty(item)

        # 4. X·ª≠ l√Ω context
        context_length = 0
        qdrant_context = None

        # 4a. N·∫øu l√† RAG (c√≥ context s·∫µn)
        if question_type == "RAG":
            context = classification.get("context", "")
            context_length = len(context)

            # Apply semantic filtering cho context d√†i
            if context_length > 10000:
                filtered_context, metadata = self.context_filter.filter_context(
                    context=context,
                    question=classification.get("question", question),
                    max_chunks=4,
                    max_chars=1000,
                )
                classification["context"] = filtered_context
                context_length = len(filtered_context)

                if verbose:
                    print(
                        f"Context filtered: {metadata['original_length']} ‚Üí {metadata['filtered_length']} chars"
                    )

        # 4b. N·∫øu l√† MULTI_DOMAIN, retrieve context t·ª´ Qdrant
        elif question_type == "MULTI_DOMAIN":
            qdrant_context = self._retrieve_qdrant_context(
                question=question,
                question_type=question_type,
                subtype=subtype,
                verbose=verbose,
            )
            if qdrant_context:
                context_length = len(qdrant_context)

        # 5. Ch·ªçn model
        selected_model = HybridModelSelector.select_model(
            question_type=question_type,
            difficulty=difficulty,
            context_length=context_length,
            strategy=self.strategy,
            subtype=subtype,
        )

        if verbose:
            print(
                f"Type: {question_type}, Subtype: {subtype}, Difficulty: {difficulty}"
            )
            print(f"Selected model: {selected_model}")

        # 6. Build prompt
        # Ch·ªçn context ph√π h·ª£p
        if question_type == "RAG":
            context = classification.get("context")
        elif question_type == "MULTI_DOMAIN":
            context = qdrant_context
        else:
            context = None

        prompt = self.prompt_selector.select_prompt(
            question_type=question_type,
            question=classification.get("question", question),
            choices=choices,
            context=context,
            subtype=subtype,
            model_type=(
                selected_model if selected_model != "small_with_fallback" else "small"
            ),
        )

        # 7. Get response
        if selected_model == "small_with_fallback":
            result = self._process_with_fallback(
                prompt=prompt,
                question_type=question_type,
                choices=choices,
                verbose=verbose,
            )
        else:
            result = self._get_model_response(
                model_type=selected_model,
                prompt=prompt,
                question_type=question_type,
                choices=choices,
                verbose=verbose,
            )

        # 8. Add metadata
        result["qid"] = qid
        result["ground_truth"] = ground_truth
        result["type"] = question_type
        result["subtype"] = subtype
        result["difficulty"] = difficulty
        result["qdrant_used"] = qdrant_context is not None

        # Check correctness
        if ground_truth and result["predicted"]:
            result["correct"] = result["predicted"] == ground_truth
        else:
            result["correct"] = None

        self.stats["total_processed"] += 1

        if verbose:
            print(f"Predicted: {result['predicted']}")
            if ground_truth:
                print(f"Ground truth: {ground_truth}")
                print(f"Correct: {result['correct']}")

        return result

    def _get_model_response(
        self,
        model_type: str,
        prompt: str,
        question_type: str,
        choices: List[str],
        verbose: bool = False,
        allow_fallback: bool = True,
    ) -> Dict[str, Any]:

        model = self._get_model(model_type)

        # Adjust parameters based on question type
        if question_type in ["STEM", "PRECISION_CRITICAL"]:
            # C·∫ßn nhi·ªÅu token h∆°n cho t√≠nh to√°n v√† gi·∫£i th√≠ch
            max_tokens = 1024
            temperature = 0.05  # Nhi·ªát ƒë·ªô th·∫•p cho ƒë·ªô ch√≠nh x√°c cao
        elif question_type == "COMPULSORY":
            # C·∫ßn ·ªïn ƒë·ªãnh v√† an to√†n
            max_tokens = 512
            temperature = 0.0  # Kh√¥ng c√≥ ng·∫´u nhi√™n
        else:
            # RAG, MULTI_DOMAIN
            max_tokens = 256
            temperature = 0.1

        # Call model
        try:
            response = model.get_completion(
                prompt=prompt, temperature=temperature, max_tokens=max_tokens
            )

            if verbose:
                print(f"Model response ({model_type}): {response}")

            # Extract answer
            valid_labels = self.formatter.get_valid_labels(choices)
            predicted = self.answer_extractor.extract(response, valid_labels)

            # Validate
            is_valid = (
                self.formatter.validate_answer(predicted, choices)
                if predicted
                else False
            )

            if not is_valid:
                model = self._get_model("small")
                response = model.get_completion(
                    prompt=prompt, temperature=temperature, max_tokens=max_tokens
                )
                if verbose:
                    print(f"Model response (small): {response}")
                predicted = self.answer_extractor.extract(response, valid_labels)

            # Calculate confidence
            confidence = self.confidence_scorer.calculate_confidence(
                model_response=response,
                extracted_answer=predicted or "",
                valid_labels=valid_labels,
            )

            # Update stats
            if model_type == "small":
                self.stats["small_used"] += 1
            else:
                self.stats["large_used"] += 1

            return {
                "predicted": predicted,
                "raw_response": response,
                "model_used": model_type,
                "confidence": confidence,
                "extraction_failed": not is_valid,
            }

        except Exception as e:
            error_str = str(e)
            print(f"Error calling {model_type} model: {error_str}")
            is_rate_limit = any(
                keyword in error_str.lower()
                for keyword in ["rate limit", "quota", "401", "429", "unauthorized"]
            )

            if is_rate_limit and model_type == "large" and allow_fallback:
                print("‚ö†Ô∏è Large model h·∫øt quota! T·ª± ƒë·ªông chuy·ªÉn sang small model...")
                if verbose:
                    print("Fallback reason: Rate limit exceeded on large model")

                # Retry v·ªõi small model
                small_result = self._get_model_response(
                    model_type="small",
                    prompt=prompt,
                    question_type=question_type,
                    choices=choices,
                    verbose=verbose,
                    allow_fallback=False,  # Kh√¥ng fallback n·ªØa
                )

                # Th√™m metadata v·ªÅ vi·ªác fallback
                small_result["rate_limit_fallback"] = True
                small_result["original_model"] = "large"
                self.stats["fallback_triggered"] += 1
                self.stats["rate_limit_fallback"] += 1

                return small_result

            # N·∫øu kh√¥ng th·ªÉ fallback ho·∫∑c kh√¥ng ph·∫£i rate limit
            return {
                "predicted": None,
                "raw_response": None,
                "model_used": model_type,
                "confidence": 0.0,
                "extraction_failed": True,
                "error": error_str,
                "rate_limit_fallback": False,
            }

    def _process_with_fallback(
        self, prompt: str, question_type: str, choices: List[str], verbose: bool = False
    ) -> Dict[str, Any]:

        if verbose:
            print("Trying small model first...")

        # Try small first
        small_result = self._get_model_response(
            model_type="small",
            prompt=prompt,
            question_type=question_type,
            choices=choices,
            verbose=verbose,
        )

        # Check if fallback needed
        need_fallback = False
        fallback_reason = None

        if small_result["predicted"] is None:
            need_fallback = True
            fallback_reason = "extraction_failed"
        elif small_result["confidence"] < 0.6:
            need_fallback = True
            fallback_reason = "low_confidence"

        if need_fallback:
            if verbose:
                print(f"Fallback to large model (reason: {fallback_reason})")

            # Retry with large
            large_result = self._get_model_response(
                model_type="large",
                prompt=prompt,
                question_type=question_type,
                choices=choices,
                verbose=verbose,
            )

            large_result["fallback_used"] = True
            large_result["fallback_reason"] = fallback_reason
            large_result["small_confidence"] = small_result["confidence"]

            self.stats["fallback_triggered"] += 1

            return large_result

        small_result["fallback_used"] = False
        return small_result

    def get_statistics(self) -> Dict[str, Any]:
        """L·∫•y th·ªëng k√™ s·ª≠ d·ª•ng model"""
        total = self.stats["total_processed"]
        if total == 0:
            return self.stats

        return {
            **self.stats,
            "small_percentage": f"{self.stats['small_used']/total*100:.1f}%",
            "large_percentage": f"{self.stats['large_used']/total*100:.1f}%",
            "fallback_rate": f"{self.stats['fallback_triggered']/total*100:.1f}%",
            "rate_limit_fallback_rate": f"{self.stats['rate_limit_fallback']/total*100:.1f}%",
            "compulsory_detection_rate": f"{self.stats['compulsory_detected']/total*100:.1f}%",
        }
